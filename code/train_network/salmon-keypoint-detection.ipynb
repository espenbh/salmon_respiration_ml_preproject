{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Define macros\nBATCH_SIZE = 4\nLABEL_NAMES = ['ljaw', 'ujaw', 'eye']\nLABEL_MAP = dict([(y,x) for x,y in enumerate((LABEL_NAMES))])\nNUM_KEYPOINTS = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install pycocotools\n!pip install git+https://github.com/gautamchitnis/cocoapi.git@cocodataset-master#subdirectory=PythonAPI","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set device\n\nimport tensorflow as tf\nimport torch\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nGPUs = tf.config.list_physical_devices('GPU')\n\nif len(GPUs) > 0: \n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    for gpu in gpus: \n        tf.config.experimental.set_memory_growth(gpu, True)\n        print('The following device is configured: ')\n        print(gpu)\nelse:\n    print('Warning: No GPUs configured')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create pytorch dataloader\n\nimport os\nimport numpy as np\nimport torch\nimport torchvision\nimport json\nfrom PIL import Image\nimport random\n\n# In order to be able to use a batch with labels of different sizes (i.e. 2 and 3 salmon bounding boxes)\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\nclass salmonTrainDataset(torch.utils.data.Dataset):\n    def __init__(self, root):\n        self.root = root # Data main folder\n        self.transforms = torchvision.transforms.ToTensor()\n        self.imgs = list(sorted(os.listdir(os.path.join(self.root, 'images')))) # Image folder\n        self.targets = list(sorted(os.listdir(os.path.join(self.root, 'labels')))) # Label folder\n\n    def __getitem__(self, idx):\n        # Input: {keypoints: [[[]]], bboxes: [[]], areas: []}\n        # Output: images: (tensor([[[]]]), ...) and\n        # targets: ({keypoints: tensor([[[x, y, 1], [x, y, 1], [x, y, 1]], ...]), boxes: tensor([[xmin, ymin, xmax, ymax], ...]), bbox_labels: tensor([]), \n        # labels: tensor([]), image_id: tensor([]), iscrowd: tensor([])}...)\n        \n        # Import labels and images\n        img_path = os.path.join(self.root, 'images', self.imgs[idx])\n        label_path = os.path.join(self.root, 'labels', self.targets[idx])\n        \n        with open(label_path) as f:\n            label = json.load(f)\n        img = Image.open(img_path)\n        \n        # To tensor\n        target = {}\n        target['keypoints'] = torch.as_tensor(label['keypoints'], dtype=torch.float32)\n        target['boxes'] = torch.as_tensor(label['bboxes'], dtype=torch.float32)\n        target['bbox_labels'] = torch.as_tensor([1]*len(label['bboxes']), dtype=torch.int64)\n        target['labels'] = torch.as_tensor([1]*len(label['bboxes']), dtype=torch.int64)\n        target['image_id'] = torch.as_tensor([idx])\n        #target['area'] = torch.as_tensor(area, dtype=torch.float32)\n        target['iscrowd'] = torch.as_tensor([False]*len(label['bboxes']), dtype=torch.int64)\n        img_tensor = torchvision.transforms.functional.pil_to_tensor(img)\n        img_tensor = torch.div(img_tensor, 255)\n        img_tensor = img_tensor.to(device)\n        return img_tensor, target\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get test sample from data loader\n\ndataset = salmonTrainDataset('../input/aug-lab-data-2100-salmon-refined/aug_lab_data')\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nimages, targets = next(iter(data_loader))\n\nprint(targets[0]['boxes'].shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize data from the data loader\nimport matplotlib.pyplot as plt\nimport cv2\nimport torchvision.transforms as T\n\ndef draw_label_on_img(images, targets, ax, batch_size = BATCH_SIZE,  iou_threshold = 0.1):\n    toPilImg = T.ToPILImage()\n    \n    for idx, img in enumerate(images):\n        # Transform image tensors to arrays\n        img = torch.as_tensor(img.detach().cpu().numpy())\n        img = np.array(toPilImg(img).convert('RGB'))\n        # Perfroms NMS. Outpur is indices of bounding boxes. If no scores exists, all indices are returned.\n        if 'scores' in targets[idx]:\n            nms = torchvision.ops.nms(targets[idx]['boxes'], targets[idx]['scores'], iou_threshold = iou_threshold)\n            nms = nms.detach().cpu().numpy()\n        else:\n            nms = list(range(len(targets[idx]['boxes'])))\n        \n        # Extraxt bounding box array from tensor\n        boxes = targets[idx]['boxes'].detach().cpu().numpy()\n        \n        # Draw all valid bboxes and keypoints onto image\n        for i in nms:\n            cv2.rectangle(img, \n                tuple(boxes[i][:2].astype(int)),\n                tuple(boxes[i][2:].astype(int)), \n                (255,0,0), 5)\n            for keypoint in range(NUM_KEYPOINTS):\n                color = (255,255,255)\n                if keypoint == 0: color = (255,0,0) # ljaw\n                if keypoint == 1: color = (0,255,0) # ujaw\n                if keypoint == 2: color = (0,0,255) # eye\n                cv2.circle(img, \n                           (int(targets[idx]['keypoints'][i][keypoint][0]), int(targets[idx]['keypoints'][i][keypoint][1])), 5,\n                           color, 5)\n            ax[idx].imshow(img) \n    return ax\n\n# Call visualization function\nfig, ax = plt.subplots(ncols=BATCH_SIZE, figsize=(20,20))\nax = draw_label_on_img(images, targets, ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define model\n\nfrom torchvision.models.detection.rpn import AnchorGenerator\nanchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\nmodel = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,\n                                                               pretrained_backbone=True,\n                                                               num_keypoints=3,\n                                                               num_classes = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review model\nfrom torch.utils.tensorboard import SummaryWriter\n\nwriter = SummaryWriter()\nimages, targets = next(iter(data_loader))\nprint(model.roi_heads)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform and plot untrained forward pass\n\n# Untrained forward pass\nimages, targets = next(iter(data_loader))\nmodel.to(device).eval()\noutput = model(images)\n\n# Plot untrained forward pass\nfig, ax = plt.subplots(ncols=BATCH_SIZE, figsize=(20,20))\nax = draw_label_on_img(images, output, ax)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import helper functions from pyvision\n\nimport sys\nsys.path.insert(1, '../input/pytorch-vision/pytorch_vision')\n\nfrom engine import train_one_epoch, evaluate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\n\nmodel.to(device).train()\n\n# Choose trainable parameters, optimizer and learning rate\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005,\n                            momentum=0.9, weight_decay=0.0005)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                            step_size=3,\n                                            gamma=0.1)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    print(\"Start an epoch\")\n    # train for one epoch, printing every 10 iterations\n    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n    # update the learning rate\n    lr_scheduler.step()\n    torch.save(model.state_dict(), 'salmon_keypoint_detection')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test model (after loading it into input as a dataset)\n\nmodel.load_state_dict(torch.load('../input/salmon-keypoint-detection-10-epoch/salmon_keypoint_detection_10_epoch', map_location=device))\nimages, targets = next(iter(data_loader))\n\nmodel.to(device).eval()\noutput = model(images)\nprint(images)\nprint(output)\n\nfig, ax = plt.subplots(ncols=BATCH_SIZE, figsize=(20,20))\nax = draw_label_on_img(images, output, ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}